{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_img = (28,28)\n",
    "Epochs = 100\n",
    "Lr_Rate = 1e-3\n",
    "Batch_Size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=Batch_Size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=Batch_Size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        #Encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256) # Input image (28*28 = 784)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=16)\n",
    "\n",
    "        #Decoder \n",
    "        self.dec1 = nn.Linear(in_features=16, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784) # Output image (28*28 = 784)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        x = F.relu(self.enc5(x))\n",
    "\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=Lr_Rate)\n",
    "device=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "def make_dir():\n",
    "    image_dir = 'MNIST_Out_Images'\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "\n",
    "def save_decod_img(img, epoch):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, './MNIST_Out_Images/Autoencoder_image{}.png'.format(epoch))\n",
    "\n",
    "\n",
    "def training(model, train_loader, Epochs):\n",
    "    train_loss = []\n",
    "    for epoch in range(Epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            img, _ = data\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(img)\n",
    "            loss = criterion(outputs, img)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        loss = running_loss / len(train_loader)\n",
    "        train_loss.append(loss)\n",
    "        print('Epoch {} of {}, Train Loss: {:.3f}'.format(\n",
    "            epoch+1, Epochs, loss))\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            save_decod_img(outputs.cpu().data, epoch)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "def test_image_reconstruct(model, test_loader):\n",
    "     for batch in test_loader:\n",
    "        img, _ = batch\n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        outputs = model(img)\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        save_image(outputs, 'MNIST_reconstruction.png')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "model.to(device)\n",
    "make_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100, Train Loss: 0.922\n",
      "Epoch 2 of 100, Train Loss: 0.917\n",
      "Epoch 3 of 100, Train Loss: 0.912\n",
      "Epoch 4 of 100, Train Loss: 0.908\n",
      "Epoch 5 of 100, Train Loss: 0.904\n",
      "Epoch 6 of 100, Train Loss: 0.902\n",
      "Epoch 7 of 100, Train Loss: 0.900\n",
      "Epoch 8 of 100, Train Loss: 0.898\n",
      "Epoch 9 of 100, Train Loss: 0.897\n",
      "Epoch 10 of 100, Train Loss: 0.896\n",
      "Epoch 11 of 100, Train Loss: 0.896\n",
      "Epoch 12 of 100, Train Loss: 0.895\n",
      "Epoch 13 of 100, Train Loss: 0.894\n",
      "Epoch 14 of 100, Train Loss: 0.893\n",
      "Epoch 15 of 100, Train Loss: 0.892\n",
      "Epoch 16 of 100, Train Loss: 0.892\n",
      "Epoch 17 of 100, Train Loss: 0.892\n",
      "Epoch 18 of 100, Train Loss: 0.891\n",
      "Epoch 19 of 100, Train Loss: 0.891\n",
      "Epoch 20 of 100, Train Loss: 0.890\n",
      "Epoch 21 of 100, Train Loss: 0.890\n",
      "Epoch 22 of 100, Train Loss: 0.890\n",
      "Epoch 23 of 100, Train Loss: 0.890\n",
      "Epoch 24 of 100, Train Loss: 0.889\n",
      "Epoch 25 of 100, Train Loss: 0.889\n",
      "Epoch 26 of 100, Train Loss: 0.889\n",
      "Epoch 27 of 100, Train Loss: 0.888\n",
      "Epoch 28 of 100, Train Loss: 0.888\n",
      "Epoch 29 of 100, Train Loss: 0.888\n",
      "Epoch 30 of 100, Train Loss: 0.888\n",
      "Epoch 31 of 100, Train Loss: 0.888\n",
      "Epoch 32 of 100, Train Loss: 0.888\n",
      "Epoch 33 of 100, Train Loss: 0.887\n",
      "Epoch 34 of 100, Train Loss: 0.887\n",
      "Epoch 35 of 100, Train Loss: 0.887\n",
      "Epoch 36 of 100, Train Loss: 0.887\n",
      "Epoch 37 of 100, Train Loss: 0.887\n",
      "Epoch 38 of 100, Train Loss: 0.887\n",
      "Epoch 39 of 100, Train Loss: 0.887\n",
      "Epoch 40 of 100, Train Loss: 0.887\n",
      "Epoch 41 of 100, Train Loss: 0.887\n",
      "Epoch 42 of 100, Train Loss: 0.886\n",
      "Epoch 43 of 100, Train Loss: 0.886\n",
      "Epoch 44 of 100, Train Loss: 0.886\n",
      "Epoch 45 of 100, Train Loss: 0.886\n",
      "Epoch 46 of 100, Train Loss: 0.886\n",
      "Epoch 47 of 100, Train Loss: 0.886\n",
      "Epoch 48 of 100, Train Loss: 0.886\n",
      "Epoch 49 of 100, Train Loss: 0.886\n",
      "Epoch 50 of 100, Train Loss: 0.886\n",
      "Epoch 51 of 100, Train Loss: 0.885\n",
      "Epoch 52 of 100, Train Loss: 0.885\n",
      "Epoch 53 of 100, Train Loss: 0.885\n",
      "Epoch 54 of 100, Train Loss: 0.885\n",
      "Epoch 55 of 100, Train Loss: 0.885\n",
      "Epoch 56 of 100, Train Loss: 0.885\n",
      "Epoch 57 of 100, Train Loss: 0.885\n",
      "Epoch 58 of 100, Train Loss: 0.885\n",
      "Epoch 59 of 100, Train Loss: 0.885\n",
      "Epoch 60 of 100, Train Loss: 0.885\n",
      "Epoch 61 of 100, Train Loss: 0.885\n",
      "Epoch 62 of 100, Train Loss: 0.884\n",
      "Epoch 63 of 100, Train Loss: 0.884\n",
      "Epoch 64 of 100, Train Loss: 0.884\n",
      "Epoch 65 of 100, Train Loss: 0.884\n",
      "Epoch 66 of 100, Train Loss: 0.884\n",
      "Epoch 67 of 100, Train Loss: 0.884\n",
      "Epoch 68 of 100, Train Loss: 0.884\n",
      "Epoch 69 of 100, Train Loss: 0.884\n",
      "Epoch 70 of 100, Train Loss: 0.884\n",
      "Epoch 71 of 100, Train Loss: 0.884\n",
      "Epoch 72 of 100, Train Loss: 0.884\n",
      "Epoch 73 of 100, Train Loss: 0.884\n",
      "Epoch 74 of 100, Train Loss: 0.884\n",
      "Epoch 75 of 100, Train Loss: 0.884\n",
      "Epoch 76 of 100, Train Loss: 0.884\n",
      "Epoch 77 of 100, Train Loss: 0.884\n",
      "Epoch 78 of 100, Train Loss: 0.884\n",
      "Epoch 79 of 100, Train Loss: 0.884\n",
      "Epoch 80 of 100, Train Loss: 0.884\n",
      "Epoch 81 of 100, Train Loss: 0.883\n",
      "Epoch 82 of 100, Train Loss: 0.883\n",
      "Epoch 83 of 100, Train Loss: 0.883\n",
      "Epoch 84 of 100, Train Loss: 0.883\n",
      "Epoch 85 of 100, Train Loss: 0.883\n",
      "Epoch 86 of 100, Train Loss: 0.883\n",
      "Epoch 87 of 100, Train Loss: 0.883\n",
      "Epoch 88 of 100, Train Loss: 0.883\n",
      "Epoch 89 of 100, Train Loss: 0.883\n",
      "Epoch 90 of 100, Train Loss: 0.883\n",
      "Epoch 91 of 100, Train Loss: 0.883\n",
      "Epoch 92 of 100, Train Loss: 0.883\n",
      "Epoch 93 of 100, Train Loss: 0.883\n",
      "Epoch 94 of 100, Train Loss: 0.883\n",
      "Epoch 95 of 100, Train Loss: 0.883\n",
      "Epoch 96 of 100, Train Loss: 0.883\n",
      "Epoch 97 of 100, Train Loss: 0.883\n",
      "Epoch 98 of 100, Train Loss: 0.883\n",
      "Epoch 99 of 100, Train Loss: 0.883\n",
      "Epoch 100 of 100, Train Loss: 0.883\n"
     ]
    }
   ],
   "source": [
    "train_loss = training(model, train_loader, Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (enc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (enc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (enc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (enc4): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (enc5): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (dec1): Linear(in_features=16, out_features=32, bias=True)\n",
       "  (dec2): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (dec3): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (dec4): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (dec5): Linear(in_features=256, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, 'model')\n",
    "model = torch.load('model')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b227a5a74a4b15a27a68108b04370906cedb0fa979dfe90452a198bd1f9dc829"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
